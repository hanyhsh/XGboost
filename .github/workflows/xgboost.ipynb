{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5541006",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06eec84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "student_por_df = pd.read_csv('student/student-por.csv', sep=';')\n",
    "student_por_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b259af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plt.plot(sorted(student_por_df['G3']))\n",
    "plt.title('Final Grade Distribution')\n",
    "plt.grid()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce6dbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# find all non-numerical data\n",
    "non_mueric_features = [feat for feat in list(student_por_df) if feat not in list(student_por_df._get_numeric_data())]\n",
    "for feat in non_mueric_features:\n",
    "    print(feat, ':', set(student_por_df[feat])) \n",
    "    \n",
    "   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76767e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for feat in non_mueric_features:\n",
    "    dummies = pd.get_dummies(student_por_df[feat]).rename(columns=lambda x: feat + '_' + str(x))\n",
    "    student_por_df = pd.concat([student_por_df, dummies], axis=1)\n",
    "    \n",
    "student_por_df = student_por_df[[feat for feat in list(student_por_df) if feat not in non_mueric_features]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b866b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an xgboost model\n",
    "# run simple xgboost classification model and check \n",
    "# prep modeling code\n",
    "outcome = 'G3'\n",
    "features = [feat for feat in list(student_por_df) if feat not in outcome]\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(student_por_df, \n",
    "                                                 student_por_df[outcome], \n",
    "                                                 test_size=0.3, \n",
    "                                                 random_state=42)\n",
    "\n",
    "\n",
    "import xgboost  as xgb\n",
    "xgb_params = {\n",
    "    'eta': 0.01,\n",
    "    'max_depth': 3,\n",
    "    'subsample': 0.7,\n",
    "    'colsample_bytree': 0.7,\n",
    "    'objective': 'reg:linear',\n",
    "    'seed' : 0\n",
    "}\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train[features], y_train, feature_names = features)\n",
    "dtest = xgb.DMatrix(X_test[features], y_test, feature_names = features)\n",
    "evals = [(dtrain,'train'),(dtest,'eval')]\n",
    "xgb_model = xgb.train (params = xgb_params,\n",
    "              dtrain = dtrain,\n",
    "              num_boost_round = 2000,\n",
    "              verbose_eval=50, \n",
    "              early_stopping_rounds = 500,\n",
    "              evals=evals,\n",
    "              #feval = f1_score_cust,\n",
    "              maximize = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6068fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# plot the important features  \n",
    "fig, ax = plt.subplots(figsize=(6,9))\n",
    "xgb.plot_importance(xgb_model,  height=0.8, ax=ax, max_num_features=20)\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847a9d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# get dataframe version of important feature for model \n",
    "xgb_fea_imp=pd.DataFrame(list(xgb_model.get_fscore().items()),\n",
    "columns=['feature','importance']).sort_values('importance', ascending=False)\n",
    "xgb_fea_imp.head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72c9c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(xgb_model.predict(dtest)[0:10])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3743a4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_features = list(xgb_fea_imp['feature'].values[0:40])\n",
    "key_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a8951e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Take students with a predicted final score of less than 10 over 20\n",
    "predicted_students_in_trouble = X_test[X_test['G3'] < 10]\n",
    "\n",
    "# See which feature they landed well below or well above peers\n",
    "for index, row in predicted_students_in_trouble.iterrows():\n",
    "    print('Student ID:', index)\n",
    "    for feat in key_features:\n",
    "        if row[feat] < student_por_df[feat].quantile(0.25):\n",
    "            print('\\t', 'Below:', feat, row[feat], 'Class:', \n",
    "                  np.round(np.mean(student_por_df[feat]),2))\n",
    "        if row[feat] > student_por_df[feat].quantile(0.75):\n",
    "            print('\\t','Above:', feat, row[feat], 'Class:', \n",
    "                  np.round(np.mean(student_por_df[feat]),2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312f54c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "lower_limit_threshold = 0.25\n",
    "\n",
    "# See which feature they landed well below or well above peers\n",
    "for index, row in predicted_students_in_trouble.iterrows():\n",
    "    student_id = index\n",
    "    important_low_features = []\n",
    " \n",
    "    for feat in key_features:\n",
    "        if row[feat] < student_por_df[feat].quantile(lower_limit_threshold):\n",
    "            important_low_features.append(feat)\n",
    "    \n",
    "    # create new data set for this student\n",
    "    at_risk_student = pd.DataFrame(row[important_low_features]).T\n",
    "    at_risk_student['Retention_Risk'] = True\n",
    "    student_mean = pd.DataFrame(student_por_df[important_low_features].mean(axis=0)).T\n",
    "    student_mean['Retention_Risk'] = False\n",
    "    student_profile = pd.concat([at_risk_student,student_mean])\n",
    "    student_profile = pd.melt(student_profile, id_vars=\"Retention_Risk\")\n",
    "    \n",
    "    print('Student ID:', student_id)\n",
    "    sns.catplot(x='variable', y='value', hue='Retention_Risk',data=student_profile, kind='bar', \n",
    "                palette=sns.color_palette(['blue', 'red']))\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcb268b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# See which feature they landed well below or well above peers\n",
    "upper_limit_threshold = 0.75\n",
    "\n",
    "for index, row in predicted_students_in_trouble.iterrows():\n",
    "    student_id = index\n",
    "    important_above_features = []\n",
    " \n",
    "    for feat in key_features:\n",
    "        if row[feat] > student_por_df[feat].quantile(upper_limit_threshold):\n",
    "            important_above_features.append(feat)\n",
    "            \n",
    "        \n",
    "    # create new data set for this student\n",
    "    at_risk_student = pd.DataFrame(row[important_above_features]).T\n",
    "    at_risk_student['Retention_Risk'] = True\n",
    "    student_mean = pd.DataFrame(student_por_df[important_above_features].mean(axis=0)).T\n",
    "    student_mean['Retention_Risk'] = False\n",
    "    student_profile = pd.concat([at_risk_student,student_mean])\n",
    "    student_profile = pd.melt(student_profile, id_vars=\"Retention_Risk\")\n",
    "    \n",
    "    print('Student ID:', student_id)\n",
    "    sns.catplot(x='variable', y='value', hue='Retention_Risk',data=student_profile, kind='bar', \n",
    "                palette=sns.color_palette(['blue', 'red']))\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d178d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9607eff6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e54713",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82f2bfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe2cea7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87839fc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0634f78c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a95f49c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
